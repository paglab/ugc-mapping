{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721f659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# ---------------------------------------------------------------------\n",
    "#      UNet Script for Ground-Cover Classification\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "import os, gc, time, random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch, torch.nn as nn, torch.optim as optim, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.metrics import (accuracy_score, cohen_kappa_score,\n",
    "                             confusion_matrix, f1_score)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --------------------------- portable paths -------------------------\n",
    "REPO_ROOT   = Path(__file__).resolve().parent\n",
    "DATASET_DIR = Path(os.getenv(\"DATASET\",  REPO_ROOT / \"Dataset\" / \"patches\"))\n",
    "OUTPUT_DIR  = Path(os.getenv(\"UNET_OUTPUT\",   REPO_ROOT / \"Output\"))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_image_dir = DATASET_DIR / \"images\" / \"train\"\n",
    "train_mask_dir  = DATASET_DIR / \"masks\"  / \"train\"\n",
    "val_image_dir   = DATASET_DIR / \"images\" / \"validation\"\n",
    "val_mask_dir    = DATASET_DIR / \"masks\"  / \"validation\"\n",
    "test_image_dir  = DATASET_DIR / \"images\" / \"test\"\n",
    "test_mask_dir   = DATASET_DIR / \"masks\"  / \"test\"\n",
    "\n",
    "for d in (train_image_dir, train_mask_dir,\n",
    "          val_image_dir,   val_mask_dir,\n",
    "          test_image_dir,  test_mask_dir):\n",
    "    if not d.exists():\n",
    "        raise FileNotFoundError(f\"Expected directory missing: {d}\")\n",
    "\n",
    "# ------------------------------ transforms --------------------------\n",
    "class ToTensorNoScaling:\n",
    "    def __call__(self, pic):\n",
    "        return torch.tensor(np.array(pic), dtype=torch.long)\n",
    "\n",
    "img_tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "msk_tf = transforms.Compose([ToTensorNoScaling()]) \n",
    "\n",
    "# ------------------------------- dataset ----------------------------\n",
    "class PatchDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads paired image and mask patches from specified directories.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_dir, mask_dir,\n",
    "                 image_transform=None, mask_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "        # Ensure images and masks match in count (and sorted order)\n",
    "        self.image_list = sorted(os.listdir(image_dir))\n",
    "        self.mask_list  = sorted(os.listdir(mask_dir))\n",
    "        if len(self.image_list) != len(self.mask_list):\n",
    "            raise ValueError(\n",
    "                f\"Mismatch: {len(self.image_list)} images vs. {len(self.mask_list)} masks\\n\"\n",
    "                f\"  images: {image_dir}\\n  masks:  {mask_dir}\"\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.image_list[idx])\n",
    "        mask_path  = os.path.join(self.mask_dir, self.mask_list[idx])\n",
    "        \n",
    "        # --- load image GeoTIFF ---\n",
    "        with rasterio.open(image_path) as src:\n",
    "            img_arr = src.read()                        \n",
    "            img_arr = np.transpose(img_arr, (1, 2, 0)) \n",
    "            image   = Image.fromarray(img_arr.astype(np.uint8))\n",
    "\n",
    "        # --- load mask GeoTIFF ---\n",
    "        with rasterio.open(mask_path) as src:\n",
    "            msk_arr = src.read(1)                       \n",
    "            mask    = Image.fromarray(msk_arr.astype(np.uint8))\n",
    "\n",
    "        # --- apply transforms ---\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask  = self.mask_transform(mask)\n",
    "\n",
    "        return image, mask \n",
    "\n",
    "# ------------------------------ loaders -----------------------------\n",
    "train_loader = DataLoader(PatchDataset(train_image_dir, train_mask_dir,\n",
    "                                       img_tf, msk_tf),\n",
    "                          batch_size=16, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(PatchDataset(val_image_dir,   val_mask_dir,\n",
    "                                       img_tf, msk_tf),\n",
    "                          batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader  = DataLoader(PatchDataset(test_image_dir,  test_mask_dir,\n",
    "                                       img_tf, msk_tf),\n",
    "                          batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ---------------------- model / loss / optimiser --------------------\n",
    "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = smp.Unet(encoder_name=\"resnet50\", encoder_weights=\"imagenet\", in_channels=3, classes=9).to(device)\n",
    "# Set ignore_index=0 to ignore background pixels in loss computation\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "# Reduce LR on plateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "scaler = GradScaler() \n",
    "\n",
    "# ------------------------------ training ----------------------------\n",
    "best_val_loss, num_epochs = float('inf'), 25\n",
    "best_model_path = OUTPUT_DIR / \"best_model_unet.pth\"\n",
    "epoch_stats, start_train = [], time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    print(f\"\\nEpoch {epoch + 1} of {num_epochs} started.\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Training Phase\n",
    "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1} started.\")\n",
    "        try:\n",
    "            images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving data to device at Training Batch {batch_idx + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, masks)\n",
    "        # NaN check\n",
    "        if torch.isnan(loss):\n",
    "            print(f\"[Epoch {epoch+1} Batch {batch_idx+1}] NaN loss â€“ skipped\")\n",
    "            continue\n",
    "        scaler.scale(loss).backward()\n",
    "        # gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch + 1}, Batch {batch_idx + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    print(f\"Training Loss (Epoch {epoch + 1}): {train_loss:.4f}\")\n",
    "\n",
    "    # Validation Phase with Aggregated Loss Calculation\n",
    "    print(\"Starting validation...\")\n",
    "    model.eval()\n",
    "    total_valid_loss = 0.0\n",
    "    total_valid_pixels = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, masks) in enumerate(val_loader):\n",
    "            print(f\"Validation Batch {batch_idx + 1} started.\")\n",
    "            try:\n",
    "                images, masks = images.to(device, non_blocking=True), masks.to(device, non_blocking=True)\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving data to device at Validation Batch {batch_idx + 1}: {e}\")\n",
    "                continue\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                # Resize outputs to match the mask size\n",
    "                outputs = F.interpolate(outputs, size=masks.shape[1:], mode='bilinear', align_corners=False)\n",
    "            \n",
    "            # Compute per-pixel loss without reduction\n",
    "            per_pixel_loss = F.cross_entropy(outputs, masks, ignore_index=0, reduction='none')\n",
    "            # Create mask for valid (non-background) pixels\n",
    "            valid_mask = (masks != 0)\n",
    "            valid_count = valid_mask.sum().item()\n",
    "            if valid_count > 0:\n",
    "                batch_loss = per_pixel_loss[valid_mask].sum().item()\n",
    "                total_valid_loss += batch_loss\n",
    "                total_valid_pixels += valid_count\n",
    "            # Also collect predictions and labels for accuracy metrics\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy().flatten()\n",
    "            labels = masks.cpu().numpy().flatten()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "            print(f\"Validation Batch {batch_idx + 1} completed.\")\n",
    "\n",
    "    # Compute aggregated validation loss over all valid pixels\n",
    "    if total_valid_pixels > 0:\n",
    "        val_loss = total_valid_loss / total_valid_pixels\n",
    "    else:\n",
    "        val_loss = 0.0\n",
    "    print(f\"Validation Loss (Epoch {epoch + 1}): {val_loss:.4f}\")\n",
    "\n",
    "    # Calculate Accuracy and Kappa (excluding background)\n",
    "    filtered_preds = [p for (p, l) in zip(all_preds, all_labels) if l != 0]\n",
    "    filtered_labels = [l for l in all_labels if l != 0]\n",
    "    if len(filtered_labels) > 0:\n",
    "        val_acc = accuracy_score(filtered_labels, filtered_preds)\n",
    "        val_kappa = cohen_kappa_score(filtered_labels, filtered_preds)\n",
    "        print(f\"Validation Accuracy (excl. background): {val_acc:.4f}\")\n",
    "        print(f\"Validation Kappa (excl. background): {val_kappa:.4f}\")\n",
    "    else:\n",
    "        val_acc, val_kappa = 0.0, 0.0\n",
    "    print(f\"Val Acc: {val_acc:.4f}, Val Kappa: {val_kappa:.4f}\")\n",
    "    \n",
    "    # LR scheduler\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch} done, LR={current_lr:.1e}\")\n",
    "    \n",
    "\n",
    "    # Save Best Model if validation loss improves\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Saved best model at epoch {epoch + 1} with val_loss={val_loss:.4f} to {best_model_path}\")\n",
    "    else:\n",
    "        print(f\"Validation loss did not improve at epoch {epoch + 1}. Current val_loss={val_loss:.4f}, Best val_loss={best_val_loss:.4f}\")\n",
    "\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch + 1} finished in {epoch_time:.2f} seconds\")\n",
    "    epoch_stats.append((epoch + 1, train_loss, val_loss, val_acc, val_kappa, current_lr))\n",
    "\n",
    "training_total_time = time.time() - training_start\n",
    "print(f\"\\nTotal Training Time: {training_total_time:.2f} seconds\")\n",
    "\n",
    "# ------------ save epoch log ----------------\n",
    "loss_file_path = os.path.join(OUTPUT_DIR, \"Loss_UNet.txt\")\n",
    "with open(loss_file_path, 'w') as f:\n",
    "    f.write(\"Epoch\\tTraining Loss\\tValidation Loss\\tAccuracy\\tKappa\\t\\tLR\\n\")\n",
    "    for epoch_num, train_loss, val_loss, val_acc, val_kappa, lr in epoch_stats:\n",
    "        f.write(f\"{epoch_num}\t{train_loss:.4f}\t{val_loss:.4f}\t{val_acc:.4f}\t{val_kappa:.4f}\t{lr:.1e}\")\n",
    "print(f\"Metrics saved to: {loss_file_path}\")\n",
    "\n",
    "# --------------------------- testing -------------------------------\n",
    "print(\"\\nStarting test evaluation...\")\n",
    "# Check if the best model file exists; if not, save the current model state as the best model.\n",
    "if not os.path.exists(best_model_path):\n",
    "    torch.save(model.state_dict(), best_model_path)\n",
    "    print(f\"Best model not found. Saved current model state to {best_model_path}\")\n",
    "else:\n",
    "    # Load the best model for evaluation.\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    print(f\"Loaded best model from {best_model_path} for evaluation.\")\n",
    "\n",
    "model.eval()\n",
    "test_preds, test_labels = [], []\n",
    "test_start = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, masks) in enumerate(test_loader):\n",
    "        print(f\"Test Batch {batch_idx + 1} started.\")\n",
    "        try:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving data to device at Test Batch {batch_idx + 1}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        outputs = model(images)\n",
    "        # Resize outputs to match the mask size\n",
    "        outputs = F.interpolate(outputs, size=masks.shape[1:], mode='bilinear', align_corners=False)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy().flatten()\n",
    "        labels = masks.cpu().numpy().flatten()\n",
    "        test_preds.extend(preds)\n",
    "        test_labels.extend(labels)\n",
    "        print(f\"Test Batch {batch_idx + 1} completed.\")\n",
    "\n",
    "test_time = time.time() - test_start\n",
    "\n",
    "# ----------------------Overall Metrics (Excluding Background)--------------------\n",
    "\n",
    "test_labels_no_bg  = [l for l in test_labels if l != 0]\n",
    "test_preds_no_bg   = [p for (p, l) in zip(test_preds, test_labels) if l != 0]\n",
    "\n",
    "if len(test_labels_no_bg) > 0:\n",
    "    overall_accuracy = accuracy_score(test_labels_no_bg, test_preds_no_bg)\n",
    "    overall_kappa    = cohen_kappa_score(test_labels_no_bg, test_preds_no_bg)\n",
    "    overall_f1       = f1_score(test_labels_no_bg, test_preds_no_bg, average='weighted')\n",
    "else:\n",
    "    overall_accuracy = 0.0\n",
    "    overall_kappa    = 0.0\n",
    "    overall_f1       = 0.0\n",
    "\n",
    "print(f\"Test Accuracy (Excl. Background): {overall_accuracy:.4f}\")\n",
    "print(f\"Test Cohen's Kappa (Excl. Background): {overall_kappa:.4f}\")\n",
    "print(f\"Test Weighted F1-Score (Excl. Background): {overall_f1:.4f}\")\n",
    "print(f\"Test Evaluation Time: {test_time:.2f} seconds\")\n",
    "\n",
    "# ----------------------Confusion Matrix -------------------------\n",
    "conf_matrix = confusion_matrix(test_labels, test_preds)\n",
    "conf_matrix_path = os.path.join(OUTPUT_DIR, 'confusion_matrix_unet.txt')\n",
    "np.savetxt(conf_matrix_path, conf_matrix, delimiter=',', fmt='%d')\n",
    "print(f\"Confusion matrix saved to: {conf_matrix_path}\")\n",
    "\n",
    "# ----------------------Per-Class Metrics -------------------------\n",
    "n_classes = 9\n",
    "dice_scores = []\n",
    "iou_scores = []\n",
    "per_class_f1 = f1_score(test_labels, test_preds, average=None, labels=range(n_classes))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    TP = conf_matrix[i, i]\n",
    "    FP = np.sum(conf_matrix[:, i]) - TP\n",
    "    FN = np.sum(conf_matrix[i, :]) - TP\n",
    "    denom_dice = (2 * TP + FP + FN)\n",
    "    denom_iou  = (TP + FP + FN)\n",
    "    dice = (2.0 * TP / denom_dice) if denom_dice > 0 else 0\n",
    "    iou  = (TP / denom_iou) if denom_iou > 0 else 0\n",
    "    dice_scores.append(dice)\n",
    "    iou_scores.append(iou)\n",
    "\n",
    "# -----------------Save Evaluation Metrics and Computational Times-----------------------\n",
    "total_comp_time = training_total_time + test_time\n",
    "\n",
    "metrics_str  = \"Overall Metrics (Excluding Background):\\n\"\n",
    "metrics_str += f\"Accuracy: {overall_accuracy:.4f}\\n\"\n",
    "metrics_str += f\"Cohen's Kappa: {overall_kappa:.4f}\\n\"\n",
    "metrics_str += f\"Weighted F1-Score: {overall_f1:.4f}\\n\\n\"\n",
    "metrics_str += \"Per-Class Metrics (0..8):\\n\"\n",
    "metrics_str += \"Class\\tF1-Score\\tDice Coefficient\\tIoU (Jaccard Index)\\n\"\n",
    "for i in range(n_classes):\n",
    "    metrics_str += f\"{i}\\t{per_class_f1[i]:.4f}\\t\\t{dice_scores[i]:.4f}\\t\\t{iou_scores[i]:.4f}\\n\"\n",
    "metrics_str += \"\\nComputational Time Metrics (in seconds):\\n\"\n",
    "metrics_str += f\"Total Training Time: {training_total_time:.2f}\\n\"\n",
    "metrics_str += f\"Test Evaluation Time: {test_time:.2f}\\n\"\n",
    "metrics_str += f\"Total Computational Time: {total_comp_time:.2f}\\n\"\n",
    "\n",
    "metrics_file_path = os.path.join(OUTPUT_DIR, \"evaluation_metrics_unet.txt\")\n",
    "with open(metrics_file_path, 'w') as f:\n",
    "    f.write(metrics_str)\n",
    "print(f\"Evaluation metrics saved to: {metrics_file_path}\")\n",
    "\n",
    "gc.collect()\n",
    "print(\"\\nDone! Training & evaluation completed successfully.\")\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
